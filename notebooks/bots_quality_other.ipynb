{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import ujson\n",
    "import os\n",
    "from os.path import join\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from hyperopt import hp\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing import sequence\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy.random import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "from sklearn.metrics import mean_squared_error, log_loss, accuracy_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from random import shuffle, randint\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_format = \"train_{}.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATADIR = \"/workspace/data/bots/turing-data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#0.62"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATES = [\"20170724\", \"20170725\", \"20170726\"]\n",
    "VAL_DATES = [\"20170726\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA = [join(DATADIR, file_format.format(x)) for x in DATES]\n",
    "VAL_DATA = [join(DATADIR, file_format.format(x)) for x in VAL_DATES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_data = [ujson.load(open(x)) for x in DATA]\n",
    "val_data = [ujson.load(open(x)) for x in VAL_DATA]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_replies(diag, user):\n",
    "    replies = list(filter(lambda x: x[\"userId\"] == user, diag[\"thread\"]))\n",
    "    return replies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi\n",
      "What is your name?\n"
     ]
    }
   ],
   "source": [
    "for r in get_replies(all_data[0][2], \"Bob\"):\n",
    "    print(r[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAIN_PART = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_PAD = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_score(diag, user):\n",
    "    score = list(filter(lambda x: x[\"userId\"] == user, diag[\"evaluation\"]))[0][\"quality\"]\n",
    "#     score = 1 if score >= 2 else 0\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_replies(diag, user):\n",
    "    replies = list(filter(lambda x: x[\"userId\"] == user, diag[\"thread\"]))\n",
    "    return replies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_type(diag, user):\n",
    "    u = list(filter(lambda x: x[\"id\"] == user, diag[\"users\"]))[0]['userType']\n",
    "    return 1 if u == \"Bot\" else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_features(diags, labeled=False):\n",
    "    observations = []\n",
    "    \n",
    "    for d in diags:\n",
    "        \n",
    "        for name in [\"Alice\", \"Bob\"]:\n",
    "            \n",
    "            replies = get_replies(d, name)\n",
    "            other_replies = get_replies(d, \"Alice\" if name == \"Bob\" else \"Bob\")\n",
    "            \n",
    "            if len(replies) > 0 and len(other_replies) > 0:\n",
    "                    \n",
    "                obs = {}\n",
    "                obs[\"reply\"] = \"$\".join([r[\"text\"] for r in replies])\n",
    "                obs[\"other_reply\"] = \"$\".join([r[\"text\"] for r in other_replies])\n",
    "                obs[\"user\"] = name\n",
    "                obs[\"dialogId\"] = d[\"dialogId\"]\n",
    "                \n",
    "                if labeled:\n",
    "                    obs[\"label\"] = get_score(d, name)\n",
    "                    obs[\"userType\"] = get_type(d, name)\n",
    "                    obs[\"other_label\"] = get_score(d, \"Alice\" if name == \"Bob\" else \"Bob\")\n",
    "                    obs[\"other_userType\"] = get_type(d, \"Alice\" if name == \"Bob\" else \"Bob\")\n",
    "                \n",
    "                observations.append(obs)\n",
    "    \n",
    "    return pd.DataFrame(observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_val = make_features(val_data[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_train_test(all_data, split=TRAIN_PART):\n",
    "    train_data = []\n",
    "    test_data = []\n",
    "    for al in all_data:\n",
    "        for d in al:\n",
    "            if random() < split:\n",
    "                train_data.append(d)\n",
    "            else:\n",
    "                test_data.append(d)\n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_vocab(data):\n",
    "    vocab = Counter()\n",
    "    for r in data.iterrows():\n",
    "        vocab.update(r[1][\"reply\"])\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def text_to_seq(text, char_to_ind):\n",
    "    return [char_to_ind.get(c, 0) for c in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_sequences(df, char_to_ind, max_pad=MAX_PAD):\n",
    "    for j in [\"reply\", \"other_reply\"]:\n",
    "        df[\"{}_seq\".format(j)] = df[j].apply(lambda x: text_to_seq(x, char_to_ind))\n",
    "        df[\"{}_seq_len\".format(j)] = df[\"{}_seq\".format(j)].apply(len)\n",
    "        df[\"{}_seq_padded\".format(j)] = df[\"{}_seq\".format(j)].apply(lambda x: sequence.pad_sequences([x], max_pad, padding=\"post\"))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_chat_model(n_words,\n",
    "              vocab_len,\n",
    "              emb_size,\n",
    "              filters,\n",
    "              kernel_size,\n",
    "              d_size1,\n",
    "              d_size2,\n",
    "              l_r,\n",
    "              need_more_dense1,\n",
    "              need_more_dense2):\n",
    "    \n",
    "    embedding_layer = Embedding(vocab_len, emb_size) # shared\n",
    "    \n",
    "    reply = Input(shape = (n_words,), name='n_reply')   \n",
    "    reply_e = embedding_layer(reply)\n",
    "    x = Conv1D(filters, kernel_size, activation='relu', strides=1)(reply_e) \n",
    "    xg = GlobalMaxPooling1D()(x)\n",
    "    \n",
    "    other_reply = Input(shape = (n_words,), name='n_other_reply')\n",
    "    other_reply_e = embedding_layer(other_reply)\n",
    "    xj = Conv1D(filters, kernel_size, activation='relu', strides=1)(other_reply_e)   \n",
    "    xj = GlobalMaxPooling1D()(xj)\n",
    "    \n",
    "    xg = concatenate([xg, xj])\n",
    "    \n",
    "    if need_more_dense1:\n",
    "        \n",
    "        x = Dense(d_size1, activation=\"linear\")(xg)\n",
    "        x = Dropout(0.1)(x)\n",
    "        \n",
    "        z = Dense(d_size1, activation=\"linear\")(xg)\n",
    "        z = Dropout(0.1)(z)\n",
    "    else:\n",
    "        x = xg\n",
    "        z = xg\n",
    "    \n",
    "    metric = Dense(1, activation=\"linear\", name=\"metric\")(x)\n",
    "    other_metric = Dense(1, activation=\"linear\", name=\"other_metric\")(z)\n",
    "    \n",
    "    if need_more_dense2:\n",
    "        \n",
    "        y = Dense(d_size2, activation=\"relu\")(xg)\n",
    "        y = Dropout(0.1)(y)\n",
    "        \n",
    "        z = Dense(d_size2, activation=\"relu\")(xg)\n",
    "        z = Dropout(0.1)(z)\n",
    "    else:\n",
    "        y = xg\n",
    "        z = xg\n",
    "        \n",
    "    bot = Dense(1, activation=\"sigmoid\", name=\"bot\")(y)\n",
    "    other_bot = Dense(1, activation=\"sigmoid\", name=\"other_bot\")(z)\n",
    "    \n",
    "    model = Model(inputs=[reply, other_reply], outputs=[metric, bot, other_metric, other_bot])\n",
    "    \n",
    "    model.compile(loss={\"metric\": \"mse\", \"other_metric\": \"mse\",\n",
    "                        \"bot\": \"binary_crossentropy\", \"other_bot\": \"binary_crossentropy\"},\n",
    "                  optimizer=Adam(l_r), metrics=[\"accuracy\"], loss_weights={\"metric\": 1,\n",
    "                                                                           \"bot\": 10,\n",
    "                                                                           \"other_metric\": 1,\n",
    "                                                                           \"other_bot\": 10})\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def score(all_data, k_fold, params):\n",
    "    \n",
    "    print(params)\n",
    "    \n",
    "    mses = []\n",
    "    rrs = []\n",
    "    mses_o = []\n",
    "    rrs_o = []\n",
    "    \n",
    "    for i in range(k_fold):\n",
    "        \n",
    "        train_data, test_data = get_train_test(all_data)\n",
    "        shuffle(train_data)\n",
    "        shuffle(test_data)\n",
    "        df_train = make_features(train_data, True)\n",
    "        df_test = make_features(test_data, True)\n",
    "\n",
    "        vocab = get_vocab(df_train)  \n",
    "        char_to_ind = {c[0]: i + 1 for i, c in enumerate(vocab.most_common())}\n",
    "        ind_to_char = {i: c for c, i in char_to_ind.items()}\n",
    "\n",
    "        df_train = add_sequences(df_train, char_to_ind, int(params[\"pad_size\"]))\n",
    "        df_test = add_sequences(df_test, char_to_ind, int(params[\"pad_size\"]))\n",
    "\n",
    "        y_train_score = df_train[\"label\"].values\n",
    "        y_test_score = df_test[\"label\"].values\n",
    "        \n",
    "        y_train_score_o = df_train[\"other_label\"].values\n",
    "        y_test_score_o = df_test[\"other_label\"].values\n",
    "\n",
    "        y_train_bot = df_train[\"userType\"].values\n",
    "        y_test_bot = df_test[\"userType\"].values\n",
    "        \n",
    "        y_train_bot_o = df_train[\"other_userType\"].values\n",
    "        y_test_bot_o = df_test[\"other_userType\"].values\n",
    "\n",
    "        x_train_r = np.vstack(df_train[\"reply_seq_padded\"].values)\n",
    "        x_train_o = np.vstack(df_train[\"other_reply_seq_padded\"].values)\n",
    "        \n",
    "        x_test_r = np.vstack(df_test[\"reply_seq_padded\"].values)\n",
    "        x_test_o = np.vstack(df_test[\"other_reply_seq_padded\"].values)\n",
    "\n",
    "        model = get_chat_model(int(params[\"pad_size\"]),\n",
    "                               len(char_to_ind) + 1,\n",
    "                               int(params[\"emb_size\"]),\n",
    "                               int(params[\"filters\"]),\n",
    "                               int(params[\"kernel_size\"]),\n",
    "                               int(params.get(\"d_size1\", 4)),\n",
    "                               int(params.get(\"d_size2\", 4)),\n",
    "                               params[\"lr\"],\n",
    "                               params[\"need_more_dense1\"],\n",
    "                               params[\"need_more_dense2\"])\n",
    "\n",
    "        n_epochs = int(params[\"n_epochs\"])\n",
    "\n",
    "        model.fit([x_train_r, x_train_o], [y_train_score, y_train_bot, y_train_score_o, y_train_bot_o], batch_size=16, epochs=n_epochs, verbose=0)\n",
    "\n",
    "        train_preds = model.predict([x_train_r, x_train_o])\n",
    "        test_preds = model.predict([x_test_r, x_test_o])\n",
    "\n",
    "        mse_train = mean_squared_error(train_preds[0], y_train_score)\n",
    "        mse_test = mean_squared_error(test_preds[0], y_test_score)\n",
    "        \n",
    "        rr_train = roc_auc_score(y_train_bot, train_preds[1])\n",
    "        rr_test = roc_auc_score(y_test_bot, test_preds[1])\n",
    "        \n",
    "        mse_train_o = mean_squared_error(train_preds[2], y_train_score_o)\n",
    "        mse_test_o = mean_squared_error(test_preds[2], y_test_score_o)\n",
    "        \n",
    "        rr_train_o = roc_auc_score(y_train_bot_o, train_preds[3])\n",
    "        rr_test_o = roc_auc_score(y_test_bot_o, test_preds[3])\n",
    "        \n",
    "        mses.append(mse_test)\n",
    "        rrs.append(rr_test)\n",
    "        mses_o.append(mse_test_o)\n",
    "        rrs_o.append(rr_test_o)\n",
    "    \n",
    "    mean_mse = np.mean(mse_test)\n",
    "    mean_rr = np.mean(rr_test)\n",
    "    mean_mse_o = np.mean(mse_test_o)\n",
    "    mean_rr_o = np.mean(rr_test_o)\n",
    "    \n",
    "    return {'loss': mean_mse + 10 * mean_rr + mean_mse_o + 10 * mean_rr_o,\n",
    "            'bot_auc': mean_rr,\n",
    "            'metric_loss': mean_mse,\n",
    "            'other_bot_auc': mean_rr_o,\n",
    "            'other_metric_loss': mean_mse_o,\n",
    "            'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K_FOLD = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def optimize(trials):\n",
    "    space = {\n",
    "             'n_epochs' : hp.quniform('n_epochs', 200, 200, 1),\n",
    "             'emb_size' : hp.quniform('emb_size', 4, 64, 1),\n",
    "             'filters' : hp.quniform('filters', 4, 64, 4),\n",
    "             'kernel_size' : hp.quniform('kernel_size', 4, 4, 1),\n",
    "             'pad_size': hp.quniform('pad_size', 40, 200, 1),\n",
    "             'lr': hp.uniform('lr', 0.0001, 0.01),\n",
    "             'need_more_dense1': hp.choice(\"need_more_dense1\",\n",
    "                                           [True, False]),\n",
    "             'need_more_dense2': hp.choice(\"need_more_dense2\",\n",
    "                                           [True, False]),\n",
    "             }\n",
    "    best = fmin(partial(score, all_data, K_FOLD), space, algo=tpe.suggest, trials=trials, max_evals=100)\n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_epochs': 200.0, 'need_more_dense1': True, 'lr': 0.0055435120757885556, 'emb_size': 43.0, 'kernel_size': 4.0, 'need_more_dense2': False, 'filters': 44.0, 'pad_size': 168.0}\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trials = Trials()\n",
    "res = optimize(trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'emb_size': 45.0,\n",
       " 'filters': 52.0,\n",
       " 'kernel_size': 4.0,\n",
       " 'lr': 0.0008896005810278546,\n",
       " 'n_epochs': 200.0,\n",
       " 'need_more_dense1': 0,\n",
       " 'need_more_dense2': 1,\n",
       " 'pad_size': 166.0}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'book_time': datetime.datetime(2017, 7, 27, 0, 21, 2, 227000),\n",
       " 'exp_key': None,\n",
       " 'misc': {'cmd': ('domain_attachment', 'FMinIter_Domain'),\n",
       "  'idxs': {'emb_size': [2],\n",
       "   'filters': [2],\n",
       "   'kernel_size': [2],\n",
       "   'lr': [2],\n",
       "   'n_epochs': [2],\n",
       "   'need_more_dense1': [2],\n",
       "   'need_more_dense2': [2],\n",
       "   'pad_size': [2]},\n",
       "  'tid': 2,\n",
       "  'vals': {'emb_size': [12.0],\n",
       "   'filters': [8.0],\n",
       "   'kernel_size': [4.0],\n",
       "   'lr': [0.0003582588013982851],\n",
       "   'n_epochs': [200.0],\n",
       "   'need_more_dense1': [0],\n",
       "   'need_more_dense2': [1],\n",
       "   'pad_size': [70.0]},\n",
       "  'workdir': None},\n",
       " 'owner': None,\n",
       " 'refresh_time': datetime.datetime(2017, 7, 27, 0, 30, 44, 552000),\n",
       " 'result': {'bot_auc': 0.83649706457925643,\n",
       "  'loss': 22.104022975446043,\n",
       "  'metric_loss': 2.4526946763942812,\n",
       "  'other_bot_auc': 0.87162426614481414,\n",
       "  'other_metric_loss': 2.5701149918110553,\n",
       "  'status': 'ok'},\n",
       " 'spec': None,\n",
       " 'state': 2,\n",
       " 'tid': 2,\n",
       " 'version': 0}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trials.best_trial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "backup\n",
    "===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1331,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_res = pd.DataFrame({\"score\": test_preds[0].reshape(1, -1)[0], \"is_bot\": test_preds[1].reshape(1, -1)[0]})\n",
    "train_res = pd.DataFrame({\"score\": train_preds[0].reshape(1, -1)[0], \"is_bot\": train_preds[1].reshape(1, -1)[0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1332,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_res[\"label\"] = df_test[\"label\"]\n",
    "test_res[\"is_bot_real\"] = df_test[\"userType\"]\n",
    "test_res[\"dialog_id\"] = df_test[\"dialogId\"]\n",
    "test_res[\"user\"] = df_test[\"user\"]\n",
    "train_res[\"label\"] = df_train[\"label\"]\n",
    "train_res[\"is_bot_real\"] = df_train[\"userType\"]\n",
    "train_res[\"dialog_id\"] = df_train[\"dialogId\"]\n",
    "train_res[\"user\"] = df_train[\"user\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1346,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.90393013100436681"
      ]
     },
     "execution_count": 1346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test_res.is_bot_real, test_res.is_bot > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1348,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92551594746716692"
      ]
     },
     "execution_count": 1348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(test_res.is_bot_real, test_res.is_bot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1333,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_preds = model.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1334,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_res = pd.DataFrame({\"score\": val_preds[0].reshape(1, -1)[0], \"is_bot\": val_preds[1].reshape(1, -1)[0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1335,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "val_res[\"dialog_id\"] = df_val[\"dialogId\"]\n",
    "val_res[\"user\"] = df_val[\"user\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1336,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_res.to_csv(\"/workspace/data/bots/24_train.csv\")\n",
    "test_res.to_csv(\"/workspace/data/bots/25_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1337,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_res.to_csv(\"/workspace/data/bots/26_val.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
